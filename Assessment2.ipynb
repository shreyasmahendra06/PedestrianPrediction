{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a0a9c92-f499-4d30-b57b-85fc807a5203",
   "metadata": {},
   "source": [
    "# Assesment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1796796d-5211-4e54-a132-308df90d0d99",
   "metadata": {},
   "source": [
    "**Group- 14**\\\n",
    "GitHub Link- https://github.com/shreyasmahendra06/PedestrianPrediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a4f742-6ed3-461b-afd5-85583bee9e0e",
   "metadata": {},
   "source": [
    "In our project Pedestrian intention prediction for autonomous vehicles, we are dealing with videos which contain videos of pedestrians crossing the road and videos which does not include any pedestrian crossing the road. The videos are captured from the front view of a car, and the captured videos are further broken down to images which can be fed to model as train, test and validation data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75d501b-dba9-41a5-a913-a30e049cad18",
   "metadata": {},
   "source": [
    "## Data Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91129b3a-cc6a-42c2-a94a-b26dcf5d348f",
   "metadata": {},
   "source": [
    "#### What is the dataset about?\n",
    "The dataset that is used in our project is JAAD (Joint Attention in Autonomous Driving) dataset which focuses on pedestrian and driver behaviors at the point of crossing and factors that influence them. The dataset includes video clips of pedestrians crossing, pedestrians not crossing and videos that do not include pedestrians. These videos are filmed in several locations in North America and Eastern Europe represent scenes typical for everyday urban driving in various weather conditions.\n",
    "\n",
    "### Exploring other datasets \n",
    "(https://github.com/ViswanathaReddyGajjala/Datasets) \\\n",
    "There are multiple datasets which consist of pedestrians walking in the urban cities and in unconstrained environments, however, most of the dataset is collected for these datasets are from a surveillance perspective and not does not include the behavior of the driver or the factors which influence the decision making of the driver. Although the available datasets can be used to detect pedestrians or highlight the pedestrians among other objects like cyclists or cars. Where as the dataset which is used for our project focuses on the pedestrians who are crossing the road or bystanders, this type of dataset is helpful to solve specific problem for an autonomous car which would have to take decisions based on the predictions made by the model.\n",
    "\n",
    "#### How is the dataset helpful?\n",
    "The JAAD dataset contains the video clips of pedestrian behaviour while crossing the road and behavior annotations which specify behaviors for pedestrians that interact with or require attention of the driver. The dataset is analysed before by converting the videos to images by frames and later supplying it to the machine learning model for prediction. There are two labels for the images which is ***Crossing*** and ***Not Crossing***, the predictions are made based on this classification of images. With the help of the prediction made by the model, the autonomous car can take appropriate decision whether to stop the car, slow down or to keep moving.\n",
    "\n",
    "#### Dataset Attributes \n",
    "**Video Footage**- 346 HD video clips 5-12 seconds long are recorded with a bashboard camera at 30 FPS. \\\n",
    "**Video type**- mp4 file. \\\n",
    "**Total number of frames after split**- 81,954 \\\n",
    "**Frames image type**- png file. \\\n",
    "**Frames image Dimension**- 1920 X 1080 \\\n",
    "**Frames image Width**- 1920 pixels \\\n",
    "**Frames image Height**- 1080 pixels \\\n",
    "**Total number of pedestrians(which include pedestrian crossing, bystanders and group of people)**- 2,786 \\\n",
    "**Number of pedestrians who cross the street**- 495 \\\n",
    "**Number of pedestrians who do not cross the street**- 191 \\\n",
    "**Number of pedestrians with behavior annotations**- 686 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f028db-7665-4a0a-8ee8-46c2203db5b7",
   "metadata": {},
   "source": [
    "#### Distribution of Videos by class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946abe81-0bf6-4536-87d8-9a0c02780d0f",
   "metadata": {},
   "source": [
    "<img src=\"foo.jpg\" width=600 align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df95090-57af-4840-9623-38e65a380032",
   "metadata": {},
   "source": [
    "#### Distribution of Images by class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a26870-fb02-400a-8fad-017232331686",
   "metadata": {},
   "source": [
    "<img src=\"foo1.jpg\" width=600 align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb613326-e736-4688-bcb9-70b4d8a3168b",
   "metadata": {},
   "source": [
    "The distribution of the pedestrians who crosses the road is higher than the pedestrians who do not cross the road. The dataset has a higher number of pedestrians crossing when compared to pedestrians not crossing the road.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdaacbdf-b6c4-4b47-8a1e-bdc1c831c23d",
   "metadata": {},
   "source": [
    "## Data Fitness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51df7c30-7c3e-42dc-afbe-6406c10e3649",
   "metadata": {},
   "source": [
    "#### Are the data sufficient for the use in your project? \n",
    "Yes, the chosen dataset has about 346 videos which are approximately 5-12 seconds long and these videos are split into images by frames, there are about 81954 images in total which includes images of pedestrian crossing and not crossing categories. The complete image folder is close to 170 GB, which tells us that the collected data is more than sufficient for the use in our project. With this huge dataset, there are some concerning aspects such as the processing time of the model when the data is ingested to the machine learning model. \\\n",
    "The collected data could be overwhelming for the machine learning model in terms of the processing capabilities, hence we are having discussions whether to make use of the whole dataset or to pick a part of the dataset and test it locally until the model is fine tuned and import it a cloud platform to make use of the complete dataset.\n",
    "We are also planning to collect data by our own and test it on the developed model, meaning to capture videos of pedestrians crossing and not crossing and testing those images on the model which has been created.\n",
    "\n",
    "#### Can you answer the research question(s) using these data?\n",
    "The dataset focuses on two aspects\n",
    "1) Pedestrians Intention  \n",
    "2) Driving behaviour of the driver at the point of crossing \n",
    "\n",
    "The above mentioned are the two important features which helps when we are trying to answer the research problem which is, what decision should be taken by an autonomous car when a pedestrian is about to cross the road or not. \\\n",
    "The dataset also provides the behavioral annotations which are the tags for each pedestrian per frame, including actions like walking, standing, crossing, looking (at the traffic). Pedestrian Attributes which is a list of attributes provided for each pedestrian. Attributes include age, gender, clothing and accessories, direction of motion, crossing location, number of people in the group.\\\n",
    "The given information and the dataset meet the requirement to answer the research question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32bbcc5-a9bb-4336-bd22-dd381bca9476",
   "metadata": {},
   "source": [
    "## Ethical Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2a4b47-97e8-464c-b07a-fa7e726cfcdb",
   "metadata": {},
   "source": [
    "#### A. Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57da8511-6c63-4f75-81fc-23f52c013665",
   "metadata": {},
   "source": [
    "**A.1 Informed consent**: There is no information provided, whether there was an informed consent given to the human subject, where the subjects choose to participate in the experiment with a clear understanding of the data usage.\\\n",
    "**A.2 Collection bias**: There were no bias that could be introduced during the collection of the data, however there is an imbalance in the number of videos where the pedestrians are crossing the road and the number of videos where the pedestrains are not crossing the road. There are no external biases which might affect the prediction of the model. \\\n",
    "**A.3 Limit PII exposure**: The dataset consists of the pedestrians face, which can be considered as the PII of a person. However, there is no other information collected such as the address of the pedestrian or the social insurance number which can bring threat to a person."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f786b2-18c7-442a-8548-d292a1caf759",
   "metadata": {},
   "source": [
    "### B. Data Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd3e3e1-c399-4f6f-a85a-b548e108788d",
   "metadata": {},
   "source": [
    "**B.1 Data security**: The data would be stored on a cloud platform and protected under the MIT license.\\\n",
    "**B.2 Right to be forgotten**: The author of the dataset has provideded information on how to be contacted such as their email ID if an individual needs to request their personal information be removed.\\\n",
    "**B.3 Data retention plan**: The dataset is used for several research and publications, however there is no information provided if the data would be deleted after it is no longer needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5f3b6d-ce28-42d2-b14c-bac5b5c3b316",
   "metadata": {},
   "source": [
    "### C. Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06326d8f-97f3-4b02-9925-1f09743ac2c1",
   "metadata": {},
   "source": [
    "**C.1 Missing perspectives**: We have had discussions with our project guide about the road map and the final product, as of now the current proposal is to use LSTM as the base architecture. We might run into problems related to the processing time of the model, and do not see any other potential road blockers in the future at this point of time.\\\n",
    "**C.2 Dataset bias**: The collected dataset has an imbalanced class of pedestrians crossing and not crossing, as of now we are moving forward with the available dataset and check for the model's accuracy. If there is a need for more data, we will be looking for similar data from https://github.com/ViswanathaReddyGajjala/Datasets \\\n",
    "**C.3 Honest representation**: Yes the visualization and the summary statistics provided in the data quality section is representing the underlying data honestly.\\\n",
    "**C.4 Privacy in analysis**: The data with PII, which is the pedestrian's face in our project, is not publicly displayed in any place. The data is only used to analyse the behaviour of the pedestrians and train the machine learning model to make predictions.\\\n",
    "**C.5 Auditability**: We are using GitHub to record every document related to our project, GitHub holds the history of every file which provides us an ability to trace back and see any code or literature changes. Every document is pushed and committed to the main branch and a README file is added which displays every information without going through the whole repository.\\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5c677c-ed86-4e0e-89e1-1454c317a2b2",
   "metadata": {},
   "source": [
    "### D. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abe39f7-417b-42b6-9ed8-5a5c22afa3ae",
   "metadata": {},
   "source": [
    "**D.1 Proxy discrimination**: The dataset used does not have any unfairly discriminatory, the dataset only focuses on the behaviour of the pedestrian while crossing the road and there are no other attributes or variables which will be used for modeling. \\\n",
    "**D.2 Fairness across groups**: The dataset has been used by researchers for analysis and tested their model on the dataset, the model will only be predicting the behavior of the pedestrians which will effect no groups or individually or provide results unfairly.\\\n",
    "**D.3 Metric selection**: The metric we will be using to measure the performance of the model are recall, precision or F1 score. Based on the initial scores will be optimizing the model. \\\n",
    "**D.4 Explainability**: This could be a time consuming task to trace back and provide a justification of the model predictions, however this can still be performed if required. \\\n",
    "**D.5 Communicate bias**: The limitations of the model will be towards identifying any unknown object apart from a pedestrian, the models accuracy might not be 85% or higher given the magnitude of the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89ec43b-3d6f-4f19-8bde-fd77e2bcf7d0",
   "metadata": {},
   "source": [
    "## Solution implementation of the research problem\n",
    "Develop an application which refers the back-end machine learning model's predictions which is build based on the LSTM neural network to promt the autonomous vehicle to take appropriate decision based on the predicted pedestrian behaviour."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befd75fb-2ff1-4f30-b1c6-2707dcd6bff5",
   "metadata": {},
   "source": [
    "## Future data needs and Potential Challenges \n",
    "If there are any environmental changes such as change in seasons and change in traffic regulations the data need to be collected based on the weather to analyse the behavior of the pedestrians again. Data collection could become difficult if there are any changes made to the privacy policies by the government. Collecting data could potentially be a challenge as it will involve legal and ethical issues, if we are to collect any data to test our model, we need to study the available safest way to proceed with the data collection.\n",
    "Implementing this project on any cloud platform could also be a challenge as of now, given the time constraint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b730c54-e5d8-4e19-861d-2eeca6abb7da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
